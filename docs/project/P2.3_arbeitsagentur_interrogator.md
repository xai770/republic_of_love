---
id: P2.3
title: "arbeitsagentur.de Interrogator"
phase: 2
status: not_started
owner: arden
priority: CRITICAL
depends_on: []
effort: 8-12h
---

# P2.3 arbeitsagentur.de Interrogator

> ðŸš¨ **MVP BLOCKER** â€” Mysti (first real user) cannot test without real German job listings.
> Deutsche Bank postings are development test data only.

## Goal

Ingest job postings from Germany's federal employment agency. Dramatically expands job coverage beyond Deutsche Bank.

## Why This Source

- **Volume**: 1M+ active listings
- **Quality**: Structured data, verified employers
- **Coverage**: All industries, all regions
- **API**: Official REST API available

## API Access

arbeitsagentur.de provides a public API:
```
https://rest.arbeitsagentur.de/jobboerse/jobsuche-service/pc/v4/jobs
```

Authentication: OAuth2 client credentials flow

## Implementation

### 1. API Client

```python
# interrogators/arbeitsagentur.py

class ArbeitsagenturClient:
    BASE_URL = "https://rest.arbeitsagentur.de/jobboerse/jobsuche-service/pc/v4"
    
    def __init__(self):
        self.token = self._get_token()
    
    def search_jobs(self, query: str, location: str = None, page: int = 0):
        """Search for jobs matching query."""
        params = {
            'was': query,
            'wo': location,
            'page': page,
            'size': 100
        }
        return self._get('/jobs', params)
    
    def get_job_detail(self, job_id: str):
        """Get full job description."""
        return self._get(f'/jobs/{job_id}')
```

### 2. Ingestion Script

```python
# scripts/ingest_arbeitsagentur.py

SEARCH_QUERIES = [
    'IT Project Manager',
    'Data Analyst',
    'Software Developer',
    'Business Analyst',
    # ... expand based on profile skills
]

def main():
    client = ArbeitsagenturClient()
    
    for query in SEARCH_QUERIES:
        jobs = client.search_jobs(query)
        for job in jobs:
            if not posting_exists(job['refnr']):
                detail = client.get_job_detail(job['refnr'])
                save_posting(
                    source='arbeitsagentur',
                    external_id=job['refnr'],
                    title=job['titel'],
                    company=job['arbeitgeber'],
                    location=job['arbeitsort']['ort'],
                    job_description=detail['stellenbeschreibung'],
                    ...
                )
```

### 3. Schema Additions

```sql
-- Track source per posting
ALTER TABLE postings ADD COLUMN source TEXT DEFAULT 'deutsche_bank';
ALTER TABLE postings ADD COLUMN external_id TEXT;
CREATE UNIQUE INDEX idx_postings_source_external ON postings(source, external_id);
```

## Challenges

| Challenge | Solution |
|-----------|----------|
| German language | Use `job_description_en` (translate before summarizing) |
| Rate limits | Respect API limits, cache aggressively |
| Deduplication | Same job on multiple boards â†’ match by title+company+location |
| Job expiry | Check `gueltigBis` field, mark invalidated |

## Acceptance Criteria

- [ ] OAuth2 token refresh works
- [ ] Search returns results
- [ ] Job details extracted correctly
- [ ] Postings saved to database with `source='arbeitsagentur'`
- [ ] No duplicates on re-run
- [ ] German descriptions trigger translation pipeline

## Sandy's Notes

This is the volume unlock. Deutsche Bank has ~200 active postings. arbeitsagentur.de has millions.

Start with a narrow search (IT jobs in Frankfurt). Expand once pipeline handles the load.

The translation step is critical. German job descriptions must go through `job_description_en` before summarization.
