#!/usr/bin/env python3
"""
Simple Framework Test
====================

A minimal test to verify framework components work.
"""

import sys
from pathlib import Path

# Add framework to path
sys.path.insert(0, '/home/xai/Documents/republic_of_love')

def test_framework():
    """Test individual framework components"""
    
    print("üß™ Testing LLM Optimization Framework Components")
    print("=" * 50)
    
    # Test 1: Import core modules
    print("\n1Ô∏è‚É£ Testing imports...")
    try:
        from llm_optimization_framework.utils.dialogue_parser import DialogueEntry
        from llm_optimization_framework.utils.quality_assessor import QualityAssessor
        from llm_optimization_framework.core.metrics import PerformanceMetrics
        from llm_optimization_framework.configs.settings import TemplateConfigs
        print("   ‚úÖ All imports successful")
    except Exception as e:
        print(f"   ‚ùå Import failed: {e}")
        return
    
    # Test 2: Create mock data
    print("\n2Ô∏è‚É£ Creating mock dialogue entry...")
    try:
        mock_entry = DialogueEntry(
            model_name="test_model",
            test_id="concise_extraction",
            test_type="concise_extraction",
            response_text="**Your Tasks:** Test response with proper structure",
            prompt_text="Test prompt",
            processing_time=1.0,
            response_length=50,
            success=True,
            metadata={"test": True}
        )
        print(f"   ‚úÖ Created entry for {mock_entry.model_name}")
    except Exception as e:
        print(f"   ‚ùå Mock data creation failed: {e}")
        return
    
    # Test 3: Quality assessment
    print("\n3Ô∏è‚É£ Testing quality assessment...")
    try:
        quality_assessor = QualityAssessor()
        quality_score = quality_assessor.assess_quality(
            mock_entry.response_text, 
            mock_entry.test_id
        )
        print(f"   ‚úÖ Quality score: {quality_score.overall_score:.3f}")
    except Exception as e:
        print(f"   ‚ùå Quality assessment failed: {e}")
        return
    
    # Test 4: Performance metrics
    print("\n4Ô∏è‚É£ Testing performance metrics...")
    try:
        metrics_calc = PerformanceMetrics()
        model_metrics = metrics_calc.calculate_model_metrics([mock_entry], "test_model")
        print(f"   ‚úÖ Model metrics calculated: {model_metrics.overall_score:.3f}")
        print(f"   ‚úÖ Performance tier: {model_metrics.performance_tier}")
    except Exception as e:
        print(f"   ‚ùå Performance metrics failed: {e}")
        return
    
    # Test 5: Configuration
    print("\n5Ô∏è‚É£ Testing configuration...")
    try:
        config = TemplateConfigs.job_matching_specialist()
        print(f"   ‚úÖ Configuration loaded: {config.project_name}")
        print(f"   ‚úÖ Quality weight: {config.category_weights.quality}")
    except Exception as e:
        print(f"   ‚ùå Configuration failed: {e}")
        return
    
    print("\nüéâ All tests passed! Framework is working correctly.")
    print("\nüìã Summary:")
    print(f"   ‚Ä¢ DialogueEntry: ‚úÖ Working")
    print(f"   ‚Ä¢ QualityAssessor: ‚úÖ Working") 
    print(f"   ‚Ä¢ PerformanceMetrics: ‚úÖ Working")
    print(f"   ‚Ä¢ Configuration: ‚úÖ Working")
    print(f"   ‚Ä¢ Mock Quality Score: {quality_score.overall_score:.3f}")
    print(f"   ‚Ä¢ Mock Model Score: {model_metrics.overall_score:.3f}")

if __name__ == "__main__":
    test_framework()
