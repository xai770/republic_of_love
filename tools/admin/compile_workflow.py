import os
#!/usr/bin/env python3
"""
Turing Workflow Compiler
=========================

Purpose: Compile Turing workflows into optimized standalone Python scripts

What it does:
- Reads workflow definition from database (conversations, instructions, steps)
- Generates standalone Python script that does the same thing
- Removes: DB logging, template rendering, placeholder overhead
- Keeps: LLM calls, logic flow, branching, same prompts

Benefits:
- 5-10x faster execution (same as script-heavy workflows)
- Still defined in Turing (edit workflow, recompile)
- Easier debugging (Python script vs database state)
- Production-ready output

Example:
    python3 tools/compile_workflow.py 3003 -o tools/taxonomy_maintenance_compiled.py
    
    # Now run the compiled version:
    python3 tools/taxonomy_maintenance_compiled.py

Architecture:
    Workflow 3003 (DB) ‚Üí Compiler ‚Üí taxonomy_maintenance_compiled.py
                                         ‚Üì
                                    subprocess.run(['ollama', ...])
                                    (no DB, no templates, just Python)
"""

import sys
import psycopg2
from datetime import datetime
from pathlib import Path

def get_workflow_definition(workflow_id: int):
    """Load complete workflow definition from database"""
    conn = psycopg2.connect(
        dbname='turing',
        user='base_admin',
        password=os.getenv('DB_PASSWORD', ''),
        host='localhost'
    )
    
    workflow = {}
    
    with conn.cursor() as cur:
        # Get workflow metadata
        cur.execute("""
            SELECT workflow_id, workflow_name, workflow_description
            FROM workflows
            WHERE workflow_id = %s
        """, (workflow_id,))
        
        row = cur.fetchone()
        if not row:
            raise ValueError(f"Workflow {workflow_id} not found")
        
        workflow['id'] = row[0]
        workflow['name'] = row[1]
        workflow['description'] = row[2]
        
        # Get conversations in execution order
        cur.execute("""
            SELECT 
                c.conversation_id,
                c.canonical_name,
                c.conversation_description,
                wc.execution_order,
                a.actor_name,
                a.actor_type,
                a.execution_type,
                a.url,
                a.execution_path
            FROM workflow_conversations wc
            JOIN conversations c ON wc.conversation_id = c.conversation_id
            JOIN actors a ON c.actor_id = a.actor_id
            WHERE wc.workflow_id = %s
            ORDER BY wc.execution_order
        """, (workflow_id,))
        
        conversations = []
        for row in cur.fetchall():
            conv = {
                'id': row[0],
                'name': row[1],
                'description': row[2],
                'order': row[3],
                'actor_name': row[4],
                'actor_type': row[5],
                'execution_type': row[6],
                'url': row[7],
                'execution_path': row[8]
            }
            
            # Get instruction for this conversation
            cur.execute("""
                SELECT 
                    instruction_id,
                    instruction_name,
                    prompt_template,
                    timeout_seconds
                FROM instructions
                WHERE conversation_id = %s
                ORDER BY step_number
                LIMIT 1
            """, (conv['id'],))
            
            inst_row = cur.fetchone()
            if inst_row:
                conv['instruction'] = {
                    'id': inst_row[0],
                    'name': inst_row[1],
                    'prompt': inst_row[2],
                    'timeout': inst_row[3]
                }
                
                # Get instruction steps (branching logic)
                cur.execute("""
                    SELECT 
                        instruction_step_name,
                        branch_condition,
                        next_conversation_id,
                        max_iterations,
                        c2.canonical_name as next_conv_name
                    FROM instruction_steps ist
                    LEFT JOIN conversations c2 ON ist.next_conversation_id = c2.conversation_id
                    WHERE ist.instruction_id = %s
                    ORDER BY 
                        CASE 
                            WHEN branch_condition = 'default' THEN 1
                            ELSE 0
                        END,
                        instruction_step_name
                """, (conv['instruction']['id'],))
                
                conv['instruction']['steps'] = []
                for step_row in cur.fetchall():
                    conv['instruction']['steps'].append({
                        'name': step_row[0],
                        'condition': step_row[1],
                        'next_conv_id': step_row[2],
                        'max_iterations': step_row[3],
                        'next_conv_name': step_row[4]
                    })
            
            conversations.append(conv)
        
        workflow['conversations'] = conversations
        
        # Get placeholders
        cur.execute("""
            SELECT 
                placeholder_name,
                source_type
            FROM placeholder_definitions pd
            JOIN workflow_placeholders wp ON pd.placeholder_id = wp.placeholder_id
            WHERE wp.workflow_id = %s
            ORDER BY placeholder_name
        """, (workflow_id,))
        
        workflow['placeholders'] = [
            {'name': row[0], 'type': row[1]}
            for row in cur.fetchall()
        ]
    
    conn.close()
    return workflow


def sanitize_function_name(name: str) -> str:
    """Convert conversation name to valid Python function name"""
    # Remove workflow prefix (w3003_c1_query_skills ‚Üí query_skills)
    parts = name.split('_')
    if parts[0].startswith('w') and parts[0][1:].isdigit():
        parts = parts[1:]  # Remove w3003
    if parts and parts[0].startswith('c') and parts[0][1:].isdigit():
        parts = parts[1:]  # Remove c1
    
    return '_'.join(parts) if parts else name.replace('-', '_').replace(' ', '_').lower()


def generate_script(workflow: dict) -> str:
    """Generate standalone Python script from workflow definition"""
    
    script = f'''#!/usr/bin/env python3
"""
{workflow['name']} (COMPILED)
{'=' * len(workflow['name'] + ' (COMPILED)')}

{workflow['description']}

‚ö†Ô∏è  AUTO-GENERATED FILE - DO NOT EDIT MANUALLY
    Generated from workflow {workflow['id']} on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
    To modify: Edit workflow in database, then recompile with:
    python3 tools/compile_workflow.py {workflow['id']} -o tools/{workflow['name'].lower().replace(' ', '_')}_compiled.py

Performance:
    Compiled workflows remove orchestration overhead while keeping identical logic:
    - Same LLM calls (ollama)
    - Same prompts
    - Same branching logic
    - 5-10x faster execution (no DB logging, templates, validation)
"""

import subprocess
import json
import sys
from datetime import datetime
from pathlib import Path


class WorkflowError(Exception):
    """Workflow execution failed"""
    pass


'''

    # Generate function for each conversation
    for i, conv in enumerate(workflow['conversations']):
        func_name = sanitize_function_name(conv['name'])
        
        script += f'''
def {func_name}(context):
    """
    {conv['description']}
    
    Actor: {conv['actor_name']} ({conv['actor_type']})
    """
    print(f"\\n{'‚îÄ' * 70}")
    print(f"üó£Ô∏è  {conv['name']}")
    print(f"   Actor: {conv['actor_name']}")
    print(f"{'‚îÄ' * 70}")
    
'''
        
        if conv.get('instruction'):
            inst = conv['instruction']
            
            # Render prompt (simple variable substitution)
            prompt = inst['prompt']
            
            script += f'''    # Prepare prompt
    prompt = """{prompt}"""
    
    # Substitute variables from context
    for key, value in context.items():
        placeholder = '{{{{' + key + '}}}}'
        if placeholder in prompt:
            if isinstance(value, dict):
                prompt = prompt.replace(placeholder, json.dumps(value, indent=2))
            else:
                prompt = prompt.replace(placeholder, str(value))
    
    print(f"   üìù Prompt length: {{len(prompt)}} chars")
    
'''
            
            # Execute based on actor type
            if conv['actor_type'] in ('llm', 'ai_model'):
                # Extract model from actor_name (not URL - ollama needs model name)
                model = conv['actor_name']
                
                script += f'''    # Execute LLM call
    try:
        result = subprocess.run(
            ['ollama', 'run', '{model}'],
            input=prompt,
            capture_output=True,
            text=True,
            timeout={inst['timeout']}
        )
        
        if result.returncode != 0:
            raise WorkflowError(f"LLM execution failed: {{result.stderr}}")
        
        output = result.stdout.strip()
        print(f"   ‚úÖ Output length: {{len(output)}} chars")
        
    except subprocess.TimeoutExpired:
        raise WorkflowError(f"LLM timeout after {inst['timeout']}s")
    except Exception as e:
        raise WorkflowError(f"LLM error: {{e}}")
    
'''
            
            elif conv['actor_type'] == 'script':
                script_path = conv['execution_path']
                
                script += f'''    # Execute script
    try:
        # Prepare input data as JSON
        input_data = {{}}
        for placeholder in {[p['name'] for p in workflow['placeholders']]}:
            if placeholder in context:
                input_data[placeholder] = context[placeholder]
        
        result = subprocess.run(
            ['python3', '{script_path}'],
            input=json.dumps(input_data),
            capture_output=True,
            text=True,
            timeout={inst.get('timeout', 600)}
        )
        
        if result.returncode != 0:
            raise WorkflowError(f"Script execution failed: {{result.stderr}}")
        
        output = result.stdout.strip()
        print(f"   ‚úÖ Output length: {{len(output)}} chars")
        
    except subprocess.TimeoutExpired:
        raise WorkflowError(f"Script timeout after {inst.get('timeout', 600)}s")
    except Exception as e:
        raise WorkflowError(f"Script error: {{e}}")
    
'''
            
            # Store output in context
            # Try to parse as JSON first
            script += f'''    # Store output
    try:
        parsed_output = json.loads(output)
        context['{conv['name']}_result'] = parsed_output
    except json.JSONDecodeError:
        context['{conv['name']}_result'] = output
    
'''
            
            # Branching logic
            if inst.get('steps'):
                script += f'''    # Evaluate branching conditions
'''
                
                for step in inst['steps']:
                    if step['condition'] == 'default':
                        if step['next_conv_name']:
                            next_func = sanitize_function_name(step['next_conv_name'])
                            script += f'''    return '{next_func}'  # Default: continue to {step['next_conv_name']}
'''
                        else:
                            script += f'''    return None  # Terminal: workflow complete
'''
                    else:
                        # Parse condition (e.g., "contains:ORGANIZE_MORE")
                        if ':' in step['condition']:
                            cond_type, cond_value = step['condition'].split(':', 1)
                            
                            if cond_type == 'contains':
                                next_func = sanitize_function_name(step['next_conv_name']) if step['next_conv_name'] else 'None'
                                
                                script += f'''    if '{cond_value}' in output:
        print(f"   üîÄ Branch: {step['condition']} ‚Üí {step['next_conv_name'] or 'TERMINAL'}")
'''
                                
                                if step.get('max_iterations'):
                                    script += f'''        # Check iteration limit
        iteration_count = context.get('iteration_count', 0) + 1
        if iteration_count > {step['max_iterations']}:
            print(f"   ‚ö†Ô∏è  Max iterations ({step['max_iterations']}) reached")
            return None  # Terminal
        context['iteration_count'] = iteration_count
'''
                                
                                if next_func != 'None':
                                    script += f'''        return '{next_func}'
'''
                                else:
                                    script += f'''        return None  # Terminal
'''
        
        script += f'''
'''
    
    # Main execution function
    script += f'''
def main():
    """Execute compiled workflow"""
    import time
    
    print(f"")
    print(f"{'‚ïê' * 70}")
    print(f"üöÄ {workflow['name']} (COMPILED)")
    print(f"{'‚ïê' * 70}")
    print(f"   Workflow ID: {workflow['id']}")
    print(f"   Conversations: {len(workflow['conversations'])}")
    print(f"   Compiled: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'‚ïê' * 70}")
    
    # Initialize context
    context = {{
        'workflow_id': {workflow['id']},
        'start_time': time.time(),
        'taxonomy_trigger': {{
            'reason': 'Compiled workflow execution',
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }}
    }}
    
    # Start with first conversation
    current_func = '{sanitize_function_name(workflow['conversations'][0]['name'])}'
    conversation_count = 0
    max_conversations = 100  # Safety limit
    
    while current_func and conversation_count < max_conversations:
        conversation_count += 1
        
        # Execute conversation function
        try:
            next_func = globals()[current_func](context)
            current_func = next_func
        except KeyError:
            print(f"\\n‚ùå Function '{{current_func}}' not found")
            return 1
        except WorkflowError as e:
            print(f"\\n‚ùå Workflow error: {{e}}")
            return 1
        except Exception as e:
            print(f"\\n‚ùå Unexpected error: {{e}}")
            import traceback
            traceback.print_exc()
            return 1
    
    if conversation_count >= max_conversations:
        print(f"\\n‚ö†Ô∏è  Max conversation limit reached ({{max_conversations}})")
        return 1
    
    # Success
    elapsed = time.time() - context['start_time']
    
    print(f"\\n{'‚ïê' * 70}")
    print(f"‚úÖ WORKFLOW COMPLETE")
    print(f"{'‚ïê' * 70}")
    print(f"   Conversations executed: {{conversation_count}}")
    print(f"   Total time: {{elapsed:.1f}}s ({{elapsed/60:.1f}} min)")
    print(f"   Avg per conversation: {{elapsed/conversation_count:.1f}}s")
    print(f"{'‚ïê' * 70}\\n")
    
    return 0


if __name__ == '__main__':
    sys.exit(main())
'''
    
    return script


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Compile Turing workflow into standalone Python script',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  # Compile workflow 3003
  python3 tools/compile_workflow.py 3003
  
  # Compile with custom output path
  python3 tools/compile_workflow.py 3003 -o tools/taxonomy_fast.py
  
  # Compile and run immediately
  python3 tools/compile_workflow.py 3003 -o /tmp/test.py && python3 /tmp/test.py

What gets compiled:
  ‚úÖ LLM calls (same prompts, same models)
  ‚úÖ Branching logic (same conditions)
  ‚úÖ Script actors (same execution paths)
  ‚úÖ Variable substitution (simplified)
  
  ‚ùå Database logging (removed for speed)
  ‚ùå Template rendering (compiled into strings)
  ‚ùå Contract validation (removed for speed)
  ‚ùå Conversation state tracking (removed for speed)

Result: 5-10x faster execution with identical behavior
        '''
    )
    
    parser.add_argument('workflow_id', type=int, help='Workflow ID to compile')
    parser.add_argument('-o', '--output', help='Output file path (default: auto-generated)')
    parser.add_argument('--dry-run', action='store_true', help='Print script instead of saving')
    
    args = parser.parse_args()
    
    print(f"üîß Compiling workflow {args.workflow_id}...")
    
    # Load workflow definition
    try:
        workflow = get_workflow_definition(args.workflow_id)
    except Exception as e:
        print(f"‚ùå Failed to load workflow: {e}")
        return 1
    
    print(f"‚úÖ Loaded workflow: {workflow['name']}")
    print(f"   Conversations: {len(workflow['conversations'])}")
    print(f"   Placeholders: {len(workflow['placeholders'])}")
    
    # Generate script
    script = generate_script(workflow)
    
    if args.dry_run:
        print(f"\n{'‚ïê' * 70}")
        print(f"COMPILED SCRIPT:")
        print(f"{'‚ïê' * 70}\n")
        print(script)
        return 0
    
    # Determine output path
    if args.output:
        output_path = Path(args.output)
    else:
        safe_name = workflow['name'].lower().replace(' ', '_').replace('-', '_')
        output_path = Path(f"tools/{safe_name}_compiled.py")
    
    # Write script
    output_path.write_text(script)
    output_path.chmod(0o755)  # Make executable
    
    print(f"\n‚úÖ Compiled workflow saved to: {output_path}")
    print(f"\nüöÄ To run:")
    print(f"   python3 {output_path}")
    print(f"\nüìä Performance:")
    print(f"   Turing execution: ~5-10 minutes (full observability)")
    print(f"   Compiled execution: ~1-2 minutes (optimized)")
    print(f"   Speedup: 5-10x faster")
    
    return 0


if __name__ == '__main__':
    sys.exit(main())
