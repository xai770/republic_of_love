#!/usr/bin/env python3
"""
turing-dashboard - Live stats for pull_daemon execution

Shows:
- Running task types with throughput
- ETA calculation based on work remaining and current rate
- Model utilization (which model is loaded)
- Progress bars

Usage:
    turing dashboard              # One-shot display
    turing dashboard --watch      # Live updates every 10s
    turing dashboard --watch 5    # Live updates every 5s
"""

import sys
import time
import argparse
import subprocess
from pathlib import Path
from datetime import datetime, timedelta

# Project setup
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
load_dotenv(project_root / '.env')

from core.database import get_connection

# ANSI codes
CLEAR = '\033[2J\033[H'
RESET, BOLD, DIM = '\033[0m', '\033[1m', '\033[2m'
GREEN, YELLOW, RED, CYAN, MAGENTA = '\033[32m', '\033[33m', '\033[31m', '\033[36m', '\033[35m'


def get_gpu_status():
    """Get GPU utilization, temperature, and power draw."""
    try:
        result = subprocess.run(
            ['/usr/bin/nvidia-smi', '--query-gpu=utilization.gpu,temperature.gpu,power.draw,memory.used,memory.total',
             '--format=csv,noheader,nounits'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            parts = result.stdout.strip().split(', ')
            return {
                'util': int(parts[0]),
                'temp': int(parts[1]),
                'power': float(parts[2]),
                'mem_used': int(parts[3]),
                'mem_total': int(parts[4]),
                'idle': int(parts[0]) < 5  # <5% = idle
            }
    except:
        pass
    return None


def get_ollama_model():
    """Get currently loaded Ollama model."""
    try:
        import requests
        resp = requests.get('http://localhost:11434/api/ps', timeout=2)
        models = resp.json().get('models', [])
        if models:
            return models[0].get('name', 'unknown')
        return None
    except:
        return None


def get_daemon_info():
    """Get pull_daemon process info."""
    try:
        result = subprocess.run(
            ['pgrep', '-af', 'pull_daemon'],
            capture_output=True, text=True
        )
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            for line in lines:
                if 'pull_daemon.py' in line:
                    parts = line.split()
                    pid = parts[0]
                    # Extract task_type if specified
                    if '--task_type' in line:
                        idx = parts.index('--task_type') if '--task_type' in parts else -1
                        if idx >= 0 and idx + 1 < len(parts):
                            return {'pid': pid, 'task_type': parts[idx + 1]}
                    return {'pid': pid, 'task_type': None}
        return None
    except:
        return None


def format_duration(seconds):
    """Format seconds as human-readable duration."""
    if seconds < 60:
        return f"{seconds:.0f}s"
    elif seconds < 3600:
        return f"{seconds/60:.0f}m"
    elif seconds < 86400:
        hours = seconds / 3600
        return f"{hours:.1f}h"
    else:
        days = seconds / 86400
        hours = (seconds % 86400) / 3600
        return f"{days:.0f}d {hours:.0f}h"


def format_eta(seconds):
    """Format ETA as completion time."""
    if seconds <= 0:
        return "done"
    completion = datetime.now() + timedelta(seconds=seconds)
    if seconds < 86400:
        return completion.strftime("%H:%M")
    else:
        return completion.strftime("%a %H:%M")


def progress_bar(current, total, width=30):
    """Generate ASCII progress bar."""
    if total == 0:
        return f"[{'‚îÄ'*width}]"
    pct = min(current / total, 1.0)
    filled = int(width * pct)
    return f"[{'‚ñà'*filled}{'‚ñë'*(width-filled)}] {pct*100:5.1f}%"


def get_task_type_stats():
    """Get stats for all active pull-enabled THICK task types.
    
    Note: Only thick actors are executed by pull_daemon. Script actors
    need the legacy batcher system.
    """
    with get_connection() as conn:
        cur = conn.cursor()
        
        # Get task types with work - thick actors have script_path set
        cur.execute("""
            SELECT 
                tt.task_type_id,
                tt.task_type_name,
                tt.requires_model,
                tt.work_query,
                tt.scale_limit,
                tt.task_type_name as actor_name,
                'thick' as actor_type,
                (SELECT COUNT(*) FROM task_logs tl 
                 WHERE tl.task_type_id = tt.task_type_id 
                 AND tl.status = 'running' AND tl.enabled = TRUE) as running,
                (SELECT COUNT(*) FROM task_logs tl 
                 WHERE tl.task_type_id = tt.task_type_id 
                 AND tl.status = 'completed' AND tl.enabled = TRUE) as completed,
                (SELECT COUNT(*) FROM task_logs tl 
                 WHERE tl.task_type_id = tt.task_type_id 
                 AND tl.status = 'failed' AND tl.enabled = TRUE) as failed,
                -- Completed in last hour (fallback rate)
                (SELECT COUNT(*) FROM task_logs tl 
                 WHERE tl.task_type_id = tt.task_type_id 
                 AND tl.status = 'completed' AND tl.enabled = TRUE
                 AND tl.completed_at > NOW() - INTERVAL '1 hour') as completed_1h,
                -- Better rate: completed in last 10 min, extrapolated to hourly
                (SELECT COUNT(*) * 6 FROM task_logs tl 
                 WHERE tl.task_type_id = tt.task_type_id 
                 AND tl.status = 'completed' AND tl.enabled = TRUE
                 AND tl.completed_at > NOW() - INTERVAL '10 minutes') as rate_10m,
                (SELECT MIN(started_at) FROM task_logs tl 
                 WHERE tl.task_type_id = tt.task_type_id 
                 AND tl.enabled = TRUE) as started_at,
                -- Session start: first task in last 2 hours (current session)
                (SELECT MIN(started_at) FROM task_logs tl 
                 WHERE tl.task_type_id = tt.task_type_id 
                 AND tl.enabled = TRUE
                 AND tl.started_at > NOW() - INTERVAL '2 hours') as session_start
            FROM task_types tt
            WHERE tt.enabled = TRUE 
              AND tt.work_query IS NOT NULL
              AND tt.script_path IS NOT NULL
            ORDER BY tt.requires_model NULLS LAST, tt.poll_priority DESC, tt.task_type_id
        """)
        
        # Fetch ALL rows first before any secondary queries
        rows = [dict(row) for row in cur.fetchall()]
        
        # Now process each with work_query counts
        import re
        for tt in rows:
            if tt['work_query']:
                try:
                    wq = tt['work_query']
                    # Remove LIMIT clause (including placeholder style)
                    wq = re.sub(r'LIMIT\s+(\d+|:\w+)\s*$', '', wq, flags=re.IGNORECASE)
                    # Replace :placeholder (but NOT :: type casts!)
                    wq = re.sub(r':batch_size\b', '1000', wq)
                    wq = re.sub(r'(?<!:):(\w+)\b(?!:)', 'NULL', wq)  # :word but not ::word
                    
                    count_query = f"SELECT COUNT(*) as cnt FROM ({wq}) sub"
                    cur.execute(count_query)
                    result = cur.fetchone()
                    tt['work_remaining'] = result['cnt'] if result else 0
                except Exception as e:
                    tt['work_remaining'] = None
                    tt['work_query_error'] = str(e)
                    # Rollback to allow continuing
                    conn.rollback()
            else:
                tt['work_remaining'] = None
        
        return rows


def display_dashboard(watch=False):
    """Display the dashboard."""
    if watch:
        print(CLEAR, end='')
    
    now = datetime.now()
    print(f"\n{BOLD}‚ïê‚ïê‚ïê Turing Dashboard ‚ïê‚ïê‚ïê{RESET}  {now.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Daemon status
    daemon = get_daemon_info()
    if daemon:
        print(f"  {GREEN}‚óè{RESET} Daemon: PID {daemon['pid']}", end='')
        if daemon['task_type']:
            print(f" (task_type {daemon['task_type']})")
        else:
            print(" (all task types)")
    else:
        print(f"  {RED}‚óè{RESET} Daemon: {DIM}stopped{RESET}")
    
    # Ollama model
    loaded_model = get_ollama_model()
    if loaded_model:
        print(f"  {GREEN}‚óè{RESET} GPU Model: {CYAN}{loaded_model}{RESET}")
    else:
        print(f"  {DIM}‚óè{RESET} GPU Model: {DIM}none loaded{RESET}")
    
    # GPU status
    gpu = get_gpu_status()
    if gpu:
        if gpu['idle']:
            gpu_color = YELLOW
            gpu_status = "IDLE"
        elif gpu['util'] < 50:
            gpu_color = CYAN
            gpu_status = "low"
        else:
            gpu_color = GREEN
            gpu_status = "working"
        print(f"  {gpu_color}‚óè{RESET} GPU: {gpu['util']}% util, {gpu['temp']}¬∞C, {gpu['power']:.0f}W, {gpu['mem_used']}/{gpu['mem_total']}MB {gpu_color}[{gpu_status}]{RESET}")
    
    print()
    print(f"{'‚îÄ'*78}")
    
    # Task type stats - filter to what daemon is CURRENTLY working on
    task_types = get_task_type_stats()
    
    if daemon and daemon['task_type']:
        # Daemon targeting specific task type - show only that
        active_types = [tt for tt in task_types if str(tt['task_type_id']) == daemon['task_type']]
    else:
        # Daemon running all types - show only THICK actors with work remaining
        # (script actors need separate batcher, not this daemon)
        active_types = [tt for tt in task_types if (tt['work_remaining'] and tt['work_remaining'] > 0)]
    
    if not active_types:
        print(f"\n  {DIM}No active task types with work{RESET}")
        print()
        return
    
    # Group by model for model-first batching display
    model_groups = {}
    for tt in active_types:
        model = tt['requires_model'] or '__none__'
        if model not in model_groups:
            model_groups[model] = []
        model_groups[model].append(tt)
    
    # Process each model group
    for model, types in model_groups.items():
        model_display = model if model != '__none__' else '(no model)'
        
        # Check if this model is currently loaded (active)
        is_active = loaded_model and model != '__none__' and loaded_model.startswith(model.split(':')[0])
        
        if is_active:
            print(f"\n  {GREEN}‚ñ∂ {BOLD}Model: {model_display}{RESET} {GREEN}‚Üê ACTIVE{RESET}")
        else:
            print(f"\n  {DIM}‚óã Model: {model_display}{RESET} {DIM}(queued){RESET}")
        
        for tt in types:
            name = tt['task_type_name']
            completed = tt['completed']
            failed = tt['failed']
            running = tt['running']
            work_remaining = tt['work_remaining'] or 0
            
            # Calculate totals
            total = completed + work_remaining
            
            # Rate calculation with stabilization
            # If session started < 10 min ago, rate_10m is unreliable (extrapolated from partial data)
            session_start = tt.get('session_start')
            rate_10m = tt.get('rate_10m') or 0
            completed_1h = tt['completed_1h']
            
            # Check session age for rate stability
            rate_stable = True
            if session_start:
                from datetime import timezone
                now_utc = datetime.now(timezone.utc)
                if hasattr(session_start, 'tzinfo') and session_start.tzinfo is None:
                    session_start = session_start.replace(tzinfo=timezone.utc)
                session_minutes = (now_utc - session_start).total_seconds() / 60
                # Need at least 5 minutes of data for stable rate
                if session_minutes < 5:
                    rate_stable = False
            
            # Use stable rate if available
            if rate_stable and rate_10m > 0:
                throughput = rate_10m
            elif completed_1h > 0:
                throughput = completed_1h
            else:
                throughput = 0
            
            # ETA logic - only meaningful if actively running
            if running > 0 and throughput > 0 and rate_stable:
                # Stable rate - show real ETA
                eta_seconds = (work_remaining / throughput) * 3600
                eta_str = f"ETA: {format_eta(eta_seconds)} ({format_duration(eta_seconds)})"
            elif running > 0 and not rate_stable:
                # Rate not yet stable - show calculating
                eta_str = f"{DIM}ETA: calculating...{RESET}"
            elif running > 0:
                # Running but no throughput yet - estimate based on ~6/min typical
                est_rate = 360  # 6/min = 360/hr typical for LLM tasks
                eta_seconds = (work_remaining / est_rate) * 3600
                eta_str = f"{DIM}~{format_duration(eta_seconds)} (estimating){RESET}"
            elif is_active and throughput > 0:
                # In active model group, will start soon
                eta_seconds = (work_remaining / throughput) * 3600
                eta_str = f"ETA ~{format_duration(eta_seconds)} when running"
            elif work_remaining == 0:
                eta_str = f"{GREEN}complete{RESET}"
            else:
                eta_str = f"{DIM}queued{RESET}"
            
            # Header - indent under model
            running_indicator = f" {YELLOW}‚ö°{RESET}" if running > 0 else ""
            print(f"\n    {BOLD}{name}{RESET} ({tt['task_type_id']}){running_indicator}")
            
            # Progress bar
            bar = progress_bar(completed, total)
            print(f"    {bar}")
            
            # Stats line
            fail_str = f"{RED}{failed}{RESET}" if failed > 0 else f"{DIM}{failed}{RESET}"
            print(f"    Done: {GREEN}{completed}{RESET}  Left: {work_remaining}  Failed: {fail_str}  Running: {YELLOW}{running}{RESET}")
            
            # Throughput and ETA
            print(f"    Rate: {MAGENTA}{throughput}/hr{RESET}  {eta_str}")
    
    print()
    print(f"{'‚îÄ'*78}")
    
    # Summary
    total_throughput = sum(tt['completed_1h'] for tt in active_types)
    total_remaining = sum(tt['work_remaining'] or 0 for tt in active_types)
    
    print(f"\n  Total: {total_throughput}/hr across {len(active_types)} task types, {total_remaining} items remaining")
    print(f"  {DIM}Model-first batching: exhausts all work for one model before switching{RESET}")
    print()


def main():
    parser = argparse.ArgumentParser(description='Live stats dashboard')
    parser.add_argument('--watch', '-w', nargs='?', const=10, type=int, 
                        metavar='SECONDS', help='Live update mode (default: 10s)')
    parser.add_argument('--watchdog', '-W', nargs='?', const=30, type=int,
                        metavar='SECONDS', help='Watchdog mode - alert on anomalies and exit (default: 30s)')
    parser.add_argument('--restart', '-r', action='store_true',
                        help='Auto-restart daemon on death (use with --watchdog)')
    parser.add_argument('--webhook', type=str, metavar='URL',
                        help='Webhook URL for alerts (Slack/Discord compatible)')
    parser.add_argument('--circuit-breaker', '-c', nargs='?', const=20, type=int,
                        metavar='PERCENT', help='Stop daemon if failure rate exceeds threshold (default: 20%%)')
    parser.add_argument('--log', '-l', type=str, metavar='FILE',
                        help='Log watchdog events to file')
    
    args = parser.parse_args()
    
    if args.watchdog:
        run_watchdog(
            interval=args.watchdog,
            auto_restart=args.restart,
            webhook_url=args.webhook,
            circuit_breaker_pct=args.circuit_breaker,
            log_file=args.log
        )
    elif args.watch:
        try:
            while True:
                display_dashboard(watch=True)
                time.sleep(args.watch)
        except KeyboardInterrupt:
            print(f"\n{DIM}Dashboard stopped{RESET}")
    else:
        display_dashboard()


def send_webhook(url, message, is_error=True):
    """Send alert to webhook (Slack/Discord compatible)."""
    try:
        import requests
        # Slack-style payload
        payload = {
            "text": message,
            "username": "Turing Watchdog",
            "icon_emoji": ":dog:" if not is_error else ":rotating_light:"
        }
        requests.post(url, json=payload, timeout=10)
    except Exception as e:
        print(f"  {YELLOW}‚ö†{RESET} Webhook failed: {e}")


def log_event(log_file, message):
    """Append event to log file."""
    if not log_file:
        return
    try:
        with open(log_file, 'a') as f:
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            f.write(f"{timestamp} {message}\n")
    except Exception as e:
        print(f"  {YELLOW}‚ö†{RESET} Log write failed: {e}")


def get_recent_failure_rate(task_type_id, window=50):
    """Get failure rate in last N completed+failed tasks."""
    with get_connection() as conn:
        cur = conn.cursor()
        cur.execute("""
            SELECT status, COUNT(*) as n
            FROM (
                SELECT status FROM task_logs
                WHERE task_type_id = %s 
                  AND status IN ('completed', 'failed')
                  AND enabled = TRUE
                ORDER BY completed_at DESC NULLS LAST
                LIMIT %s
            ) recent
            GROUP BY status
        """, (task_type_id, window))
        
        counts = {row['status']: row['n'] for row in cur.fetchall()}
        completed = counts.get('completed', 0)
        failed = counts.get('failed', 0)
        total = completed + failed
        
        if total == 0:
            return 0.0
        return (failed / total) * 100


def get_cascade_events(since_seconds=60):
    """Check for recent cascade trigger events."""
    with get_connection() as conn:
        cur = conn.cursor()
        cur.execute("""
            SELECT table_name, attribute_name, reason, COUNT(*) as n
            FROM attribute_history
            WHERE nulled_at > NOW() - INTERVAL '%s seconds'
            GROUP BY table_name, attribute_name, reason
        """, (since_seconds,))
        return [dict(row) for row in cur.fetchall()]


def restart_daemon(task_type_id=None):
    """Attempt to restart the daemon."""
    try:
        cmd = ['python3', str(project_root / 'core' / 'wave_runner' / 'pull_daemon.py')]
        if task_type_id:
            cmd.extend(['--task_type', str(task_type_id)])
        
        # Start detached
        subprocess.Popen(
            cmd,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            start_new_session=True,
            cwd=str(project_root)
        )
        return True
    except Exception as e:
        print(f"  {RED}‚úó{RESET} Restart failed: {e}")
        return False


def run_watchdog(interval, auto_restart=False, webhook_url=None, circuit_breaker_pct=None, log_file=None):
    """Watchdog mode - monitor for anomalies and alert.
    
    Enhanced features:
    - Failure spike detection (5+ in one check)
    - Failure rate monitoring (circuit breaker)
    - GPU idle detection
    - Auto-restart on daemon death
    - Webhook alerts (Slack/Discord)
    - File logging
    - Cascade trigger detection
    """
    features = ["daemon death", "stall", "failure spike"]
    if circuit_breaker_pct:
        features.append(f"circuit breaker ({circuit_breaker_pct}%)")
    if auto_restart:
        features.append("auto-restart")
    if webhook_url:
        features.append("webhook")
    if log_file:
        features.append(f"log‚Üí{log_file}")
    
    print(f"{BOLD}üêï Watchdog mode{RESET} - checking every {interval}s")
    print(f"   Features: {', '.join(features)}")
    print()
    
    # Initialize log file
    if log_file:
        log_event(log_file, "=== Watchdog started ===")
    
    # Capture baseline
    baseline = {
        'daemon_pid': None,
        'daemon_task_type': None,
        'model': None,
        'failures': {},  # task_type_id -> failure count
        'last_completed': {},  # task_type_id -> completed count
        'stall_count': {},  # task_type_id -> consecutive zero-throughput checks
        'gpu_idle_count': 0,  # consecutive GPU idle checks while daemon running
    }
    
    # Initialize baseline
    daemon = get_daemon_info()
    if daemon:
        baseline['daemon_pid'] = daemon['pid']
        baseline['daemon_task_type'] = daemon.get('task_type')
        print(f"  {GREEN}‚óè{RESET} Daemon PID {daemon['pid']} locked in")
        log_event(log_file, f"Daemon PID {daemon['pid']} locked in")
    else:
        print(f"  {YELLOW}‚ö†{RESET} No daemon running at start")
        log_event(log_file, "No daemon running at start")
    
    model = get_ollama_model()
    if model:
        baseline['model'] = model
        print(f"  {GREEN}‚óè{RESET} Model {model} locked in")
    
    task_types = get_task_type_stats()
    for tt in task_types:
        tid = tt['task_type_id']
        baseline['failures'][tid] = tt['failed']
        baseline['last_completed'][tid] = tt['completed']
        baseline['stall_count'][tid] = 0
    
    print(f"\n  Watching... (Ctrl+C to stop)\n")
    
    try:
        while True:
            time.sleep(interval)
            
            anomalies = []
            warnings = []  # Non-fatal issues
            
            # === CHECK: Daemon alive ===
            daemon = get_daemon_info()
            if baseline['daemon_pid'] and not daemon:
                msg = f"üö® DAEMON DIED - was PID {baseline['daemon_pid']}"
                anomalies.append(msg)
                
                if auto_restart:
                    print(f"  {YELLOW}‚Üª{RESET} Attempting restart...")
                    log_event(log_file, "Daemon died, attempting restart")
                    if restart_daemon(baseline['daemon_task_type']):
                        time.sleep(3)  # Give it time to start
                        new_daemon = get_daemon_info()
                        if new_daemon:
                            baseline['daemon_pid'] = new_daemon['pid']
                            baseline['daemon_task_type'] = new_daemon.get('task_type')
                            print(f"  {GREEN}‚úì{RESET} Daemon restarted: PID {new_daemon['pid']}")
                            log_event(log_file, f"Daemon restarted: PID {new_daemon['pid']}")
                            anomalies.remove(msg)  # No longer an anomaly
                            warnings.append(f"‚ö†Ô∏è Daemon auto-restarted (was PID {baseline['daemon_pid']})")
                        
            elif daemon and baseline['daemon_pid'] and daemon['pid'] != baseline['daemon_pid']:
                # Daemon restarted externally - update baseline
                baseline['daemon_pid'] = daemon['pid']
                baseline['daemon_task_type'] = daemon.get('task_type')
                print(f"  {YELLOW}‚Üª{RESET} Daemon restarted: PID {daemon['pid']}")
                log_event(log_file, f"Daemon restarted externally: PID {daemon['pid']}")
            
            # === CHECK: Model changes ===
            model = get_ollama_model()
            if model and model != baseline['model']:
                if baseline['model']:
                    print(f"  {YELLOW}‚Üª{RESET} Model changed: {baseline['model']} ‚Üí {model}")
                    log_event(log_file, f"Model changed: {baseline['model']} ‚Üí {model}")
                baseline['model'] = model
            
            # === CHECK: GPU idle while daemon running ===
            gpu = get_gpu_status()
            if daemon and gpu:
                if gpu['idle']:
                    baseline['gpu_idle_count'] += 1
                    if baseline['gpu_idle_count'] >= 3:
                        warnings.append(f"‚ö†Ô∏è GPU idle for {baseline['gpu_idle_count']} checks while daemon running")
                else:
                    baseline['gpu_idle_count'] = 0
            else:
                baseline['gpu_idle_count'] = 0
            
            # === CHECK: Cascade triggers fired ===
            cascades = get_cascade_events(since_seconds=interval + 5)
            if cascades:
                for c in cascades:
                    warnings.append(f"‚ö†Ô∏è CASCADE: {c['n']}x {c['table_name']}.{c['attribute_name']} ({c['reason']})")
                    log_event(log_file, f"Cascade: {c['n']}x {c['table_name']}.{c['attribute_name']}")
            
            # === CHECK: Task type stats ===
            task_types = get_task_type_stats()
            if daemon and daemon.get('task_type'):
                task_types = [tt for tt in task_types if str(tt['task_type_id']) == daemon['task_type']]
            
            for tt in task_types:
                tid = tt['task_type_id']
                name = tt['task_type_name']
                
                # --- Failure spike (5+ in one check) ---
                old_fails = baseline['failures'].get(tid, 0)
                new_fails = tt['failed']
                if new_fails > old_fails:
                    delta = new_fails - old_fails
                    if delta >= 5:
                        anomalies.append(f"üö® FAILURE SPIKE - {name}: +{delta} failures in one check!")
                    else:
                        warnings.append(f"‚ö†Ô∏è New failures - {name}: +{delta} (now {new_fails} total)")
                    baseline['failures'][tid] = new_fails
                
                # --- Circuit breaker (failure rate) ---
                if circuit_breaker_pct and daemon:
                    rate = get_recent_failure_rate(tid, window=50)
                    if rate >= circuit_breaker_pct:
                        anomalies.append(f"üö® CIRCUIT BREAKER - {name}: {rate:.0f}% failure rate (threshold: {circuit_breaker_pct}%)")
                        # Kill the daemon to prevent more waste
                        try:
                            subprocess.run(['pkill', '-f', 'pull_daemon.py'], capture_output=True)
                            anomalies.append(f"üõë Daemon killed by circuit breaker")
                            log_event(log_file, f"Circuit breaker triggered: {rate:.0f}% failures, daemon killed")
                        except:
                            pass
                
                # --- Stall detection ---
                old_completed = baseline['last_completed'].get(tid, 0)
                new_completed = tt['completed']
                work_remaining = tt['work_remaining'] or 0
                
                if work_remaining > 0:  # Only check stall if there's work to do
                    if new_completed == old_completed:
                        baseline['stall_count'][tid] = baseline['stall_count'].get(tid, 0) + 1
                        if baseline['stall_count'][tid] >= 6:  # ~6 intervals with no progress
                            anomalies.append(f"üö® STALLED - {name}: no progress for {baseline['stall_count'][tid] * interval}s")
                    else:
                        baseline['stall_count'][tid] = 0
                        baseline['last_completed'][tid] = new_completed
                else:
                    baseline['stall_count'][tid] = 0
                    baseline['last_completed'][tid] = new_completed
            
            # === ALERT on anomalies ===
            if anomalies:
                # Terminal bell + visual alert
                print('\a')  # Bell
                print(f"\n{RED}{'‚ïê'*60}{RESET}")
                print(f"{RED}{BOLD}  ANOMALY DETECTED  {RESET} {datetime.now().strftime('%H:%M:%S')}")
                print(f"{RED}{'‚ïê'*60}{RESET}\n")
                for a in anomalies:
                    print(f"  {a}")
                    log_event(log_file, a)
                
                # Webhook alert
                if webhook_url:
                    msg = f"üêï *Turing Watchdog Alert*\n" + "\n".join(anomalies)
                    send_webhook(webhook_url, msg, is_error=True)
                
                print()
                sys.exit(1)
            
            # === Show warnings (non-fatal) ===
            if warnings:
                for w in warnings:
                    print(f"  {YELLOW}{w}{RESET}")
            
            # === Heartbeat ===
            now = datetime.now().strftime('%H:%M:%S')
            if daemon and daemon.get('task_type'):
                active = [tt for tt in task_types if str(tt['task_type_id']) == daemon['task_type']]
                if active:
                    tt = active[0]
                    total = tt['completed'] + (tt['work_remaining'] or 0)
                    pct = (tt['completed'] / total * 100) if total > 0 else 0
                    print(f"  {DIM}{now}{RESET} ‚úì {tt['completed']}/{total} ({pct:.1f}%) @ {tt['completed_1h']}/hr")
                    log_event(log_file, f"‚úì {tt['completed']}/{total} ({tt['completed_1h']}/hr)")
                else:
                    print(f"  {DIM}{now}{RESET} ‚úì")
            elif daemon:
                print(f"  {DIM}{now}{RESET} ‚úì daemon running")
            else:
                print(f"  {DIM}{now}{RESET} ‚úì (no daemon)")
    
    except KeyboardInterrupt:
        print(f"\n{DIM}Watchdog stopped{RESET}")
        log_event(log_file, "=== Watchdog stopped ===")


if __name__ == '__main__':
    main()
