#!/usr/bin/env python3
"""
turing-costs - LLM Cost Dashboard

Track and visualize LLM costs across task_types and time periods.
Reads from task_logs where output contains llm_calls or cost data.

Cost Tracking:
- Extracts cost/token counts from task_log.output.llm_calls
- Groups by task_type, model, time period
- Estimates costs using standard pricing

Usage:
    turing-costs                      # Today's summary
    turing-costs --week               # Last 7 days
    turing-costs --month              # Last 30 days
    turing-costs --task-type 9384     # Specific task_type
    turing-costs --model mistral      # Filter by model
    turing-costs --detail             # Per-run breakdown

Pricing (configurable):
    qwen2.5-coder:7b    - local/free (estimates $0.0001/call)
    mistral:7b          - local/free
    llama3.2:3b         - local/free
    gpt-4               - $0.03/1k input, $0.06/1k output
    claude-3-opus       - $0.015/1k input, $0.075/1k output

Author: Arden (GitHub Copilot)
Date: 2026-01-08
"""

import sys
import os
import json
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict

# Project setup
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from dotenv import load_dotenv
load_dotenv(PROJECT_ROOT / '.env')

from core.database import get_connection

# ANSI colors
RESET, BOLD, DIM = '\033[0m', '\033[1m', '\033[2m'
GREEN, YELLOW, RED, CYAN, MAGENTA = '\033[32m', '\033[33m', '\033[31m', '\033[36m', '\033[35m'

# Default pricing per 1k tokens (or per call for local models)
# Local models priced at estimated electricity cost
MODEL_PRICING = {
    # Local models (Ollama) - per-call estimate
    'qwen2.5-coder:7b': {'type': 'per_call', 'cost': 0.0001},
    'qwen2.5-coder:14b': {'type': 'per_call', 'cost': 0.0002},
    'qwen2.5:7b': {'type': 'per_call', 'cost': 0.0001},
    'mistral:7b': {'type': 'per_call', 'cost': 0.0001},
    'mistral-nemo': {'type': 'per_call', 'cost': 0.0002},
    'llama3.2:3b': {'type': 'per_call', 'cost': 0.00005},
    'llama3.2:1b': {'type': 'per_call', 'cost': 0.00003},
    'granite3.1-dense:8b': {'type': 'per_call', 'cost': 0.0001},
    
    # Cloud models - per 1k tokens
    'gpt-4': {'type': 'per_1k', 'input': 0.03, 'output': 0.06},
    'gpt-4-turbo': {'type': 'per_1k', 'input': 0.01, 'output': 0.03},
    'gpt-3.5-turbo': {'type': 'per_1k', 'input': 0.0005, 'output': 0.0015},
    'claude-3-opus': {'type': 'per_1k', 'input': 0.015, 'output': 0.075},
    'claude-3-sonnet': {'type': 'per_1k', 'input': 0.003, 'output': 0.015},
    
    # Default for unknown models
    'unknown': {'type': 'per_call', 'cost': 0.0001},
}


def estimate_cost(model: str, call_count: int = 1, input_tokens: int = 0, output_tokens: int = 0) -> float:
    """Estimate cost for LLM usage."""
    # Normalize model name
    model_lower = model.lower() if model else 'unknown'
    
    # Find matching pricing
    pricing = None
    for key in MODEL_PRICING:
        if key.lower() in model_lower or model_lower in key.lower():
            pricing = MODEL_PRICING[key]
            break
    
    if not pricing:
        pricing = MODEL_PRICING['unknown']
    
    if pricing['type'] == 'per_call':
        return pricing['cost'] * call_count
    else:
        # Per-1k token pricing
        input_cost = (input_tokens / 1000) * pricing['input']
        output_cost = (output_tokens / 1000) * pricing['output']
        return input_cost + output_cost


def extract_llm_data(output: dict) -> list:
    """Extract LLM call data from task_log output."""
    calls = []
    
    # Look for llm_calls array
    llm_calls = output.get('llm_calls', [])
    if isinstance(llm_calls, list):
        for call in llm_calls:
            calls.append({
                'model': call.get('model', 'unknown'),
                'purpose': call.get('purpose', 'unknown'),
                'input_tokens': call.get('input_tokens', 0),
                'output_tokens': call.get('output_tokens', 0),
                'duration_ms': call.get('duration_ms', 0),
            })
    
    # Also check for single model field (thick actors)
    if not calls and output.get('model'):
        calls.append({
            'model': output.get('model'),
            'purpose': 'main',
            'input_tokens': output.get('input_tokens', 0),
            'output_tokens': output.get('output_tokens', 0),
            'duration_ms': output.get('duration_ms', 0),
        })
    
    return calls


def query_costs(conn, start_date: datetime, end_date: datetime, 
                task_type_id: int = None, model_filter: str = None) -> dict:
    """Query task_logs and compute costs."""
    cur = conn.cursor()
    
    # Build query
    sql = """
        SELECT 
            tl.task_type_id,
            tt.task_type_name,
            tl.output,
            tl.created_at
        FROM task_logs tl
        JOIN task_types tt ON tl.task_type_id = tt.task_type_id
        WHERE tl.created_at >= %s AND tl.created_at < %s
    """
    params = [start_date, end_date]
    
    if task_type_id:
        sql += " AND tl.task_type_id = %s"
        params.append(task_type_id)
    
    sql += " ORDER BY tl.created_at"
    
    cur.execute(sql, params)
    
    # Aggregate results
    by_task_type = defaultdict(lambda: {
        'calls': 0, 'cost': 0.0, 'models': defaultdict(int),
        'input_tokens': 0, 'output_tokens': 0, 'duration_ms': 0
    })
    by_model = defaultdict(lambda: {'calls': 0, 'cost': 0.0})
    by_day = defaultdict(lambda: {'calls': 0, 'cost': 0.0})
    
    total_calls = 0
    total_cost = 0.0
    
    for row in cur.fetchall():
        output = row['output'] or {}
        task_type_name = row['task_type_name']
        created_at = row['created_at']
        day = created_at.strftime('%Y-%m-%d')
        
        llm_calls = extract_llm_data(output)
        
        for call in llm_calls:
            model = call['model']
            
            # Apply model filter
            if model_filter and model_filter.lower() not in model.lower():
                continue
            
            cost = estimate_cost(
                model,
                call_count=1,
                input_tokens=call.get('input_tokens', 0),
                output_tokens=call.get('output_tokens', 0)
            )
            
            # Aggregate
            by_task_type[task_type_name]['calls'] += 1
            by_task_type[task_type_name]['cost'] += cost
            by_task_type[task_type_name]['models'][model] += 1
            by_task_type[task_type_name]['input_tokens'] += call.get('input_tokens', 0)
            by_task_type[task_type_name]['output_tokens'] += call.get('output_tokens', 0)
            by_task_type[task_type_name]['duration_ms'] += call.get('duration_ms', 0)
            
            by_model[model]['calls'] += 1
            by_model[model]['cost'] += cost
            
            by_day[day]['calls'] += 1
            by_day[day]['cost'] += cost
            
            total_calls += 1
            total_cost += cost
    
    cur.close()
    
    return {
        'period': {'start': start_date, 'end': end_date},
        'total_calls': total_calls,
        'total_cost': total_cost,
        'by_task_type': dict(by_task_type),
        'by_model': dict(by_model),
        'by_day': dict(sorted(by_day.items())),
    }


def format_cost(cost: float) -> str:
    """Format cost nicely."""
    if cost < 0.01:
        return f"${cost:.5f}"
    elif cost < 1:
        return f"${cost:.3f}"
    else:
        return f"${cost:.2f}"


def print_dashboard(data: dict, detail: bool = False):
    """Print cost dashboard."""
    start = data['period']['start'].strftime('%Y-%m-%d')
    end = (data['period']['end'] - timedelta(days=1)).strftime('%Y-%m-%d')
    
    print(f"\n{BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{RESET}")
    print(f"{BOLD}  LLM Cost Dashboard: {start} to {end}{RESET}")
    print(f"{BOLD}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{RESET}")
    
    print(f"\n{CYAN}Total LLM Calls:{RESET} {data['total_calls']:,}")
    print(f"{CYAN}Estimated Cost:{RESET}  {format_cost(data['total_cost'])}")
    
    # By Task Type
    print(f"\n{BOLD}ðŸ“Š By Task Type:{RESET}")
    print(f"{'Task Type':<35} {'Calls':>10} {'Cost':>12}")
    print("-" * 60)
    
    sorted_types = sorted(data['by_task_type'].items(), 
                         key=lambda x: x[1]['cost'], reverse=True)
    
    for name, stats in sorted_types[:15]:
        display_name = name[:33] + '..' if len(name) > 35 else name
        print(f"{display_name:<35} {stats['calls']:>10,} {format_cost(stats['cost']):>12}")
    
    if len(sorted_types) > 15:
        print(f"{DIM}... and {len(sorted_types) - 15} more{RESET}")
    
    # By Model
    print(f"\n{BOLD}ðŸ¤– By Model:{RESET}")
    print(f"{'Model':<25} {'Calls':>10} {'Cost':>12}")
    print("-" * 50)
    
    for model, stats in sorted(data['by_model'].items(), 
                              key=lambda x: x[1]['cost'], reverse=True):
        print(f"{model:<25} {stats['calls']:>10,} {format_cost(stats['cost']):>12}")
    
    # By Day (if multiple days)
    if len(data['by_day']) > 1:
        print(f"\n{BOLD}ðŸ“… By Day:{RESET}")
        print(f"{'Date':<12} {'Calls':>10} {'Cost':>12}")
        print("-" * 36)
        
        for day, stats in data['by_day'].items():
            print(f"{day:<12} {stats['calls']:>10,} {format_cost(stats['cost']):>12}")
    
    print()


def main():
    parser = argparse.ArgumentParser(
        description='LLM Cost Dashboard',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    # Time period
    period = parser.add_mutually_exclusive_group()
    period.add_argument('--today', action='store_true', default=True,
                        help='Show today (default)')
    period.add_argument('--week', action='store_true',
                        help='Last 7 days')
    period.add_argument('--month', action='store_true',
                        help='Last 30 days')
    period.add_argument('--days', type=int,
                        help='Last N days')
    period.add_argument('--date', type=str,
                        help='Specific date (YYYY-MM-DD)')
    
    # Filters
    parser.add_argument('--task-type', '-t', type=int,
                        help='Filter by task_type_id')
    parser.add_argument('--model', '-m', type=str,
                        help='Filter by model name')
    parser.add_argument('--detail', '-d', action='store_true',
                        help='Show detailed breakdown')
    parser.add_argument('--json', action='store_true',
                        help='Output as JSON')
    
    args = parser.parse_args()
    
    # Determine date range
    now = datetime.now()
    end_date = now.replace(hour=23, minute=59, second=59)
    
    if args.week:
        start_date = now - timedelta(days=7)
    elif args.month:
        start_date = now - timedelta(days=30)
    elif args.days:
        start_date = now - timedelta(days=args.days)
    elif args.date:
        start_date = datetime.strptime(args.date, '%Y-%m-%d')
        end_date = start_date + timedelta(days=1)
    else:
        # Today
        start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
    
    with get_connection() as conn:
        data = query_costs(
            conn,
            start_date,
            end_date,
            task_type_id=args.task_type,
            model_filter=args.model
        )
        
        if args.json:
            # Convert dates to strings for JSON
            data['period']['start'] = data['period']['start'].isoformat()
            data['period']['end'] = data['period']['end'].isoformat()
            print(json.dumps(data, indent=2, default=str))
        else:
            print_dashboard(data, args.detail)
    
    return 0


if __name__ == '__main__':
    sys.exit(main())
